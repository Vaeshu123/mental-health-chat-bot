{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8ejOhlAm_Fy"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers torch pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n"
      ],
      "metadata": {
        "id": "183xpLfdo-1F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a9e9705-756c-4567-bbe2-10bbce9ad706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading model"
      ],
      "metadata": {
        "id": "Vl-mlDOwZgC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH = \"/content/drive/MyDrive/mental health bot/distilbert-mental-health-stratified\"\n",
        "\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(MODEL_PATH)\n",
        "model = DistilBertForSequenceClassification.from_pretrained(MODEL_PATH)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "_5e7MX0HpApX",
        "outputId": "7483d4e3-ca0f-4aa0-cc6a-496d5908b5e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Can't load tokenizer for '/content/drive/MyDrive/mental health bot/distilbert-mental-health-stratified'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/content/drive/MyDrive/mental health bot/distilbert-mental-health-stratified' is the correct path to a directory containing all relevant files for a DistilBertTokenizerFast tokenizer.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;31m# This is slightly better for only 1 file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             hf_hub_download(\n\u001b[0m\u001b[1;32m    480\u001b[0m                 \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"repo_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mvalidate_repo_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrepo_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         raise HFValidationError(\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0;34m\"Repo id must be in the form 'repo_name' or 'namespace/repo_name':\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/content/drive/MyDrive/mental health bot/distilbert-mental-health-stratified'. Use `repo_type` argument if needed.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1993\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1994\u001b[0;31m                         resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m   1995\u001b[0m                             \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \"\"\"\n\u001b[0;32m--> 322\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    531\u001b[0m         resolved_files = [\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0m_get_cache_file_to_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepo_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfull_filenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36m_get_cache_file_to_return\u001b[0;34m(path_or_repo_id, full_filename, cache_dir, revision, repo_type)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;31m# We try to see if we have a cached version (not up to date):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     resolved_file = try_to_load_from_cache(\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepo_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"repo_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mvalidate_repo_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrepo_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         raise HFValidationError(\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0;34m\"Repo id must be in the form 'repo_name' or 'namespace/repo_name':\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/content/drive/MyDrive/mental health bot/distilbert-mental-health-stratified'. Use `repo_type` argument if needed.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1821934334.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mMODEL_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/mental health bot/distilbert-mental-health-stratified\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDistilBertTokenizerFast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDistilBertForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2012\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m                         \u001b[0;31m# For any other exception, we throw a generic error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2014\u001b[0;31m                         raise OSError(\n\u001b[0m\u001b[1;32m   2015\u001b[0m                             \u001b[0;34mf\"Can't load tokenizer for '{pretrained_model_name_or_path}'. If you were trying to load it from \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2016\u001b[0m                             \u001b[0;34m\"'https://huggingface.co/models', make sure you don't have a local directory with the same name. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for '/content/drive/MyDrive/mental health bot/distilbert-mental-health-stratified'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/content/drive/MyDrive/mental health bot/distilbert-mental-health-stratified' is the correct path to a directory containing all relevant files for a DistilBertTokenizerFast tokenizer."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LABEL_NAMES = [\n",
        "    \"suicidal_ideation\",\n",
        "    \"depressive_language\",\n",
        "    \"anxiety_related\",\n",
        "    \"stress_related\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "TAzsHHRdpDYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting"
      ],
      "metadata": {
        "id": "27x7mHFOZkkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/mental health bot/test.csv\")\n",
        "\n",
        "# Combine like during training\n",
        "df[\"text\"] = df[\"title\"].fillna(\"\") + \" \" + df[\"self_text\"].fillna(\"\")\n"
      ],
      "metadata": {
        "id": "nIqpAKLSplNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(text):\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=256\n",
        "    )\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits\n",
        "\n",
        "    probs = torch.sigmoid(logits)[0]\n",
        "\n",
        "    return {\n",
        "        LABEL_NAMES[i]: float(probs[i])\n",
        "        for i in range(len(LABEL_NAMES))\n",
        "    }\n"
      ],
      "metadata": {
        "id": "TiAsoHDXpwUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "for txt in df[\"text\"]:\n",
        "    results.append(predict(txt))\n",
        "\n",
        "pred_df = pd.DataFrame(results)\n",
        "final_df = pd.concat([df, pred_df], axis=1)\n"
      ],
      "metadata": {
        "id": "l1EOLjRjpz32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_labels(row, thresh=0.5):\n",
        "    return [k for k in LABEL_NAMES if row[k] >= thresh]\n",
        "\n",
        "final_df[\"predicted_labels\"] = final_df.apply(get_labels, axis=1)\n"
      ],
      "metadata": {
        "id": "7M2g9p4Cp1u9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=final_df[['community','predicted_labels','text']]\n"
      ],
      "metadata": {
        "id": "EVzAArSgqy4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I don’t want to live anymore\"\n",
        "predict(text)\n"
      ],
      "metadata": {
        "id": "P_KuOrg1qdLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Accuracy"
      ],
      "metadata": {
        "id": "KbFbeVP_slj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "LABEL_NAMES = [\n",
        "    \"suicidal_ideation\",\n",
        "    \"depressive_language\",\n",
        "    \"anxiety_related\",\n",
        "    \"stress_related\"\n",
        "]\n",
        "\n",
        "# True labels\n",
        "y_true = final_df[LABEL_NAMES].values\n",
        "\n",
        "# Predicted probabilities → binary labels\n",
        "y_pred = (final_df[LABEL_NAMES].values >= 0.5).astype(int)\n"
      ],
      "metadata": {
        "id": "x9jfYdnD8hdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "community_to_label = {\n",
        "    \"anxiety\": \"anxiety_related\",\n",
        "    \"suicidewatch\": \"suicidal_ideation\",\n",
        "    \"depressed\": \"depressive_language\",\n",
        "    \"stressed\": \"stress_related\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "LbOlUs6pUbUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df[\"true_label\"] = final_df[\"community\"].map(community_to_label)"
      ],
      "metadata": {
        "id": "CzqMv6e4UeR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pick_one(lst):\n",
        "    if isinstance(lst, list) and len(lst) > 0:\n",
        "        return lst[0]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "final_df[\"pred_label\"] = final_df[\"predicted_labels\"].apply(pick_one)\n"
      ],
      "metadata": {
        "id": "Vc-prtetVBgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_eval = final_df.dropna(subset=[\"pred_label\", \"true_label\"])\n"
      ],
      "metadata": {
        "id": "GSL7cZ9LVeNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LABEL_NAMES = [\n",
        "    \"suicidal_ideation\",\n",
        "    \"depressive_language\",\n",
        "    \"anxiety_related\",\n",
        "    \"stress_related\"\n",
        "]\n",
        "\n",
        "label2id = {l:i for i,l in enumerate(LABEL_NAMES)}\n",
        "\n",
        "y_true = df_eval[\"true_label\"].map(label2id).values\n",
        "y_pred = df_eval[\"pred_label\"].map(label2id).values\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "acc = accuracy_score(y_true, y_pred)\n",
        "print(\"Accuracy (community-based):\", acc)\n"
      ],
      "metadata": {
        "id": "gpSNNnMEVhvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import hamming_loss\n",
        "hamming_acc = 1 - hamming_loss(y_true, y_pred)\n",
        "print(\"Hamming Accuracy:\", hamming_acc)"
      ],
      "metadata": {
        "id": "lGCYL7YpZQTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "print(\"F1 Micro   :\", f1_score(y_true, y_pred, average=\"micro\"))\n",
        "print(\"F1 Macro   :\", f1_score(y_true, y_pred, average=\"macro\"))\n",
        "print(\"F1 Weighted:\", f1_score(y_true, y_pred, average=\"weighted\"))\n"
      ],
      "metadata": {
        "id": "6Owpt-I8ZXc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Heat maps"
      ],
      "metadata": {
        "id": "pU6n0lXiXgXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "label2id = {l:i for i,l in enumerate(LABEL_NAMES)}\n",
        "\n",
        "y_true = df_eval[\"true_label\"].map(label2id).values\n",
        "y_pred = df_eval[\"pred_label\"].map(label2id).values\n"
      ],
      "metadata": {
        "id": "nxpuggP-VvRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "cm\n"
      ],
      "metadata": {
        "id": "KPw5qGUWVxFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7,6))\n",
        "plt.imshow(cm, cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix (Community vs Model Prediction)\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "\n",
        "plt.xticks(range(len(LABEL_NAMES)), LABEL_NAMES, rotation=30)\n",
        "plt.yticks(range(len(LABEL_NAMES)), LABEL_NAMES)\n",
        "\n",
        "for i in range(len(LABEL_NAMES)):\n",
        "    for j in range(len(LABEL_NAMES)):\n",
        "        plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\")\n",
        "\n",
        "plt.colorbar()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uxIaknQBVy5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_cases = [\n",
        "    \"I don’t want to live anymore\",\n",
        "    \"I want to kill myself\",\n",
        "    \"I feel empty every day\",\n",
        "    \"work stress too much\",\n",
        "    \"so tired from work\",\n",
        "    \"Deadlines make me panic.\",\n",
        "    \"Too much pressure makes me anxious.\",\n",
        "    \"I feel overwhelmed and nervous.\",\n",
        "    \"Work stress is making me panic.\"\n",
        "    \"I am anxious all the time\",\n",
        "    \"I wake up empty every day and go to bed the same way.\",\n",
        "    \"Nothing excites me anymore.\",\n",
        "    \"I feel hollow inside.\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "QpWU67f6z96m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for text in test_cases:\n",
        "    output = predict(text)   # your model function\n",
        "\n",
        "    # find label with max probability\n",
        "    max_label = max(output, key=output.get)\n",
        "    max_value = output[max_label]\n",
        "\n",
        "    print(\"Text:\", text)\n",
        "    print(\"Predicted Label:\", max_label, \"->\", round(max_value, 3))\n",
        "    print(\"-\" * 60)\n"
      ],
      "metadata": {
        "id": "158BLtCB0BCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Suicidal"
      ],
      "metadata": {
        "id": "CDOgQCieGCO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1=[\"I don’t see myself growing old.\",\n",
        "\"I feel like my story should end soon.\",\n",
        "\"Some people just aren’t meant to stay long.\",\n",
        "\"I don’t belong in this world.\",\n",
        "\"I feel like I’ve already lived enough.\"]"
      ],
      "metadata": {
        "id": "G2OXkIhm18Da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for text in t1:\n",
        "    output = predict(text)\n",
        "\n",
        "    # find label with max probability\n",
        "    max_label = max(output, key=output.get)\n",
        "    max_value = output[max_label]\n",
        "\n",
        "    print(\"Text:\", text)\n",
        "    print(\"Scores:\", output)\n",
        "    print(\"Predicted Label:\", max_label, \"->\", round(max_value, 3))\n",
        "    print(\"-\" * 60)"
      ],
      "metadata": {
        "id": "Bo2fhQmc2lal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t2=[\"I’m not suicidal but I wish I wouldn’t wake up.\",\n",
        "\"I don’t want to kill myself, I just don’t want to exist.\",\n",
        "\"I’m safe, but I hate being alive.\",\n",
        "\"I won’t hurt myself, but life feels useless.\"]"
      ],
      "metadata": {
        "id": "TJlRdLty26m7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for text in t2:\n",
        "    output = predict(text)   # your model function\n",
        "\n",
        "    # find label with max probability\n",
        "    max_label = max(output, key=output.get)\n",
        "    max_value = output[max_label]\n",
        "\n",
        "    print(\"Text:\", text)\n",
        "    print(\"Scores:\", output)\n",
        "    print(\"Predicted Label:\", max_label, \"->\", round(max_value, 3))\n",
        "    print(\"-\" * 60)"
      ],
      "metadata": {
        "id": "utAWtChF2_mN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t3=[\"I’m tired of fighting life.\",\n",
        "\"I feel like giving up on everything.\",\n",
        "\"I’m done trying.\",\n",
        "\"I can’t do this anymore.\"\n",
        "]"
      ],
      "metadata": {
        "id": "ihNeCsa63P3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for text in t3:\n",
        "    output = predict(text)\n",
        "\n",
        "    # find label with max probability\n",
        "    max_label = max(output, key=output.get)\n",
        "    max_value = output[max_label]\n",
        "\n",
        "    print(\"Text:\", text)\n",
        "    print(\"Scores:\", output)\n",
        "    print(\"Predicted Label:\", max_label, \"->\", round(max_value, 3))\n",
        "    print(\"-\" * 60)"
      ],
      "metadata": {
        "id": "l7YNjBBR3dUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t4=[\"I wake up empty every day and go to bed the same way.\",\n",
        "\"Nothing excites me anymore.\",\n",
        "\"I feel hollow inside.\",\n",
        "\"I exist, but I don’t live.\",\n",
        "\"I feel emotionally dead.\",\n",
        "]\n",
        "for text in t4:\n",
        "    output = predict(text)\n",
        "\n",
        "    # find label with max probability\n",
        "    max_label = max(output, key=output.get)\n",
        "    max_value = output[max_label]\n",
        "\n",
        "    print(\"Text:\", text)\n",
        "    print(\"Predicted Label:\", max_label, \"->\", round(max_value, 3))\n",
        "    print(\"-\" * 60)"
      ],
      "metadata": {
        "id": "rojXBJR430Gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t5=\"\"\"I don’t even know why I’m writing this. Every day feels heavy.\n",
        "I wake up tired, go through the motions, and come back feeling empty.\n",
        "People say things will get better, but I don’t believe them anymore.\n",
        "Sometimes I wonder what would happen if I just wasn’t here.\"\"\""
      ],
      "metadata": {
        "id": "MOhqkTCN4Gup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(t5)"
      ],
      "metadata": {
        "id": "CMivGh0A4YuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deppresive"
      ],
      "metadata": {
        "id": "e4GCiohNGIqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t_s=[\"I keep overthinking everything and it never stops.\",\n",
        "\"My heart races even when nothing is wrong.\",\n",
        "\"I feel nervous all the time for no reason.\",\n",
        "\"I panic about small things.\",\n",
        "\"I can’t stop worrying.\",\n",
        "\"My mind won’t shut up.\",\n",
        "\"I feel scared but don’t know why.\",\n",
        "\"I get anxious in crowds.\",\n",
        "\"I feel tense inside.\",\n",
        "\"I overthink every conversation.\",\n",
        "\"I keep imagining bad things happening.\",\n",
        "\"I feel uneasy all day.\"\n",
        "]\n",
        "for text in t_s:\n",
        "    output = predict(text)   # your model function\n",
        "\n",
        "    # find label with max probability\n",
        "    max_label = max(output, key=output.get)\n",
        "    max_value = output[max_label]\n",
        "\n",
        "    print(\"Text:\", text)\n",
        "    print(\"Scores:\", output)\n",
        "    print(\"Predicted Label:\", max_label, \"->\", int(round(max_value, 2)*100))\n",
        "    print(\"-\" * 60)"
      ],
      "metadata": {
        "id": "5uZqX_5H-Wfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## anxiety"
      ],
      "metadata": {
        "id": "hdBo8V0PGXSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t_s=[\"Deadlines make me panic.\",\n",
        "\"Too much pressure makes me anxious.\",\n",
        "\"I feel overwhelmed and nervous.\",\n",
        "\"Work stress is making me panic.\",\n",
        "\"Pressure makes my heart race.\",\n",
        "\"I’m stressed and overthinking.\",\n",
        "]\n",
        "for text in t_s:\n",
        "    output = predict(text)   # your model function\n",
        "\n",
        "    # find label with max probability\n",
        "    max_label = max(output, key=output.get)\n",
        "    max_value = output[max_label]\n",
        "\n",
        "    print(\"Text:\", text)\n",
        "    print(\"Scores:\", output)\n",
        "    print(\"Predicted Label:\", max_label, \"->\", int(round(max_value, 2)*100))\n",
        "    print(\"-\" * 60)"
      ],
      "metadata": {
        "id": "_3pudIkH_Atw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stress related"
      ],
      "metadata": {
        "id": "25l9Xc27Gg0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t_s=[\"work stress too much\",\n",
        "\"so tired from work\",\n",
        "\"deadlines again man\",\n",
        "\"too much pressure fr\",\n",
        "\"cant handle workload\",\n",
        "\"work is killing me\",\n",
        "\"need a break badly\"\n",
        "]\n",
        "\n",
        "for text in t_s:\n",
        "    output = predict(text)   # your model function\n",
        "\n",
        "    # find label with max probability\n",
        "    max_label = max(output, key=output.get)\n",
        "    max_value = output[max_label]\n",
        "\n",
        "    print(\"Text:\", text)\n",
        "    print(\"Scores:\", output)\n",
        "    print(\"Predicted Label:\", max_label, \"->\", int(round(max_value, 2)*100))\n",
        "    print(\"-\" * 60)"
      ],
      "metadata": {
        "id": "7AsCFU9o_QD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_cases = [\n",
        "    \"I don’t want to live anymore\",\n",
        "    \"I want to kill myself\",\n",
        "    \"I feel empty every day\",\n",
        "    \"work stress too much\",\n",
        "    \"so tired from work\",\n",
        "    \"deadlines again man\",\n",
        "    \"Deadlines make me panic.\",\n",
        "    \"Too much pressure makes me anxious.\",\n",
        "    \"I feel overwhelmed and nervous.\",\n",
        "    \"Work stress is making me panic.\",\n",
        "    \"There is too much responsibility on me.\",\n",
        "    \"I have too much work and no time to rest.\",\n",
        "    \"My workload is getting heavier every week.\",\n",
        "    \"I am anxious all the time\",\n",
        "    \"I wake up empty every day and go to bed the same way.\",\n",
        "    \"Nothing excites me anymore.\",\n",
        "    \"I feel hollow inside.\"\n",
        "]\n",
        "print(f\"{'Text':50} | {'Label':20} | Confidence\")\n",
        "print(\"-\"*90)\n",
        "\n",
        "for text in test_cases:\n",
        "    output = predict(text)\n",
        "\n",
        "    max_label = max(output, key=output.get)\n",
        "    max_value = output[max_label]\n",
        "\n",
        "    print(f\"{text[:48]:50} | {max_label:20} | {round(max_value*100,2)}%\")\n",
        "\n"
      ],
      "metadata": {
        "id": "kXFobrwX_l-Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}